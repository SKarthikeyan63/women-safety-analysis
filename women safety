import cv2
import mediapipe as mp
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing import image
from tensorflow.keras.applications.mobilenet_v3 import preprocess_input
import numpy as np
from pushbullet import Pushbullet

pb = Pushbullet("o.ryw7V7lcQKje7KgVR5RyXTUfCaw7XGyM")

mp_hands = mp.solutions.hands
mp_face_detection = mp.solutions.face_detection
hands = mp_hands.Hands(min_detection_confidence=0.7, min_tracking_confidence=0.5)
face_detection = mp_face_detection.FaceDetection(min_detection_confidence=0.7)

mp_drawing = mp.solutions.drawing_utils

model = load_model('gender_detection_model_mobilenetv3.keras')

face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')

cap = cv2.VideoCapture(0)

hand_open = False
hand_closed = False
head_count = 0
male_count = 0
female_count = 0

def preprocess_frame(frame):
    img = cv2.resize(frame, (224, 224))
    img_array = image.img_to_array(img)
    img_array = np.expand_dims(img_array, axis=0)
    img_array = preprocess_input(img_array)
    return img_array

while True:
    ret, frame = cap.read()
    frame = cv2.flip(frame, 1)

    if not ret:
        print("Error: Failed to capture image.")
        break

    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)

    hand_result = hands.process(rgb_frame)
    face_result = face_detection.process(rgb_frame)

    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)

    faces = face_cascade.detectMultiScale(gray_frame, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))

    head_count = 0
    male_count = 0
    female_count = 0

    if face_result.detections:
        head_count = len(face_result.detections)

        for (x, y, w, h) in faces:
            cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 0, 0), 2)

            face = frame[y:y + h, x:x + w]

            preprocessed_face = preprocess_frame(face)

            prediction = model.predict(preprocessed_face)
            gender = "female" if prediction[0] > 0.5 else "male"

            if gender == "male":
                male_count += 1
            else:
                female_count += 1

            cv2.putText(frame, f'Gender: {gender}', (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2, cv2.LINE_AA)

    cv2.putText(frame, f'Head Count: {head_count}', (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 0), 2)
    cv2.putText(frame, f'Males: {male_count}', (50, 150), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 0), 2)
    cv2.putText(frame, f'Females: {female_count}', (50, 200), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 0), 2)

    if hand_result.multi_hand_landmarks:
        for hand_landmarks in hand_result.multi_hand_landmarks:
            mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)

            thumb_tip = hand_landmarks.landmark[mp_hands.HandLandmark.THUMB_TIP].y
            index_tip = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP].y
            middle_tip = hand_landmarks.landmark[mp_hands.HandLandmark.MIDDLE_FINGER_TIP].y
            ring_tip = hand_landmarks.landmark[mp_hands.HandLandmark.RING_FINGER_TIP].y
            pinky_tip = hand_landmarks.landmark[mp_hands.HandLandmark.PINKY_TIP].y

            if (index_tip < hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_MCP].y and
                    middle_tip < hand_landmarks.landmark[mp_hands.HandLandmark.MIDDLE_FINGER_MCP].y and
                    ring_tip < hand_landmarks.landmark[mp_hands.HandLandmark.RING_FINGER_MCP].y and
                    pinky_tip < hand_landmarks.landmark[mp_hands.HandLandmark.PINKY_MCP].y):
                if not hand_open:
                    hand_open = True
                    hand_closed = False
                    print("Hand Open")
                    cv2.putText(frame, "Hand Open", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)

            elif (index_tip > hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_MCP].y and
                  middle_tip > hand_landmarks.landmark[mp_hands.HandLandmark.MIDDLE_FINGER_MCP].y and
                  ring_tip > hand_landmarks.landmark[mp_hands.HandLandmark.RING_FINGER_MCP].y and
                  pinky_tip > hand_landmarks.landmark[mp_hands.HandLandmark.PINKY_MCP].y):
                if not hand_closed and hand_open:
                    hand_closed = True
                    hand_open = False
                    print("Hand Closed - Alert Triggered!")
                    cv2.putText(frame, "Hand Closed - Alert Triggered!", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)
                    alert_message = f"Alert Triggered!\nHead Count: {head_count}\nMale: {male_count}\nFemale: {female_count}"
                    pb.push_note("Hand Closed - Alert", alert_message)

    cv2.imshow('Hand Gesture, Head Count, and Gender Detection', frame)

    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()
